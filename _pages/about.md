---
layout: about
title: About
permalink: /
subtitle: Signal Processing Engineer | Machine Learning Engineer | HCI Researcher

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
      <center>Canada</center>
      <center>
          <a href="https://www.linkedin.com/in/chuyi-hou">LinkedIn</a> | 
          <a href="https://github.com/houchuyi">GitHub</a> |
          <a href="skyhou1728@gmail.com">Email</a>
      </center>

news: true # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

My broad interests:
- Human-Computer Interaction (HCI), with a focus on developing algorithms, tools, and models for seamless human-computer interactions.
- UI/UX design and transforming text-based interactions with large language models (LLMs) into more intuitive, text-less experiences.

I carry 2 years of experience in HCI research and developing gesture-based solutions to study and improve user experience. I am currently a Signal Processing and Machine Learning Engineer at Unmodal Research Inc. and a passionate HCI researcher. I hold a Master of Engineering in Mechanical and Industrial Engineering and a Bachelor of Applied Science in Engineering Science with a Robotics Option from the University of Toronto. My strong engineering background equips me with both theoretical knowledge and practical experience.

My professional journey includes working as a project team member and research assistant at the University of Toronto, where I developed my skills in Python, SQL, MATLAB, and ROS. At Unmodal Research Inc., I expanded my expertise in C programming, microcontroller programming, firmware development, and utilizing a variety of sensors such as EMG, IMU, IR cameras, and force-sensitive resistors (FSR). Additionally, I have broadened my technical skills to include Swift UI iOS app programming, UI/UX design, LLM cloud development and deployment, and Python GUI programming. I am also skilled in product photography and video editing.

Driven by a passion for innovation, I have worked on cutting-edge Computer Vision and Machine Learning projects. I am dedicated to advancing signal processing and machine learning, leveraging my diverse skill set to solve complex challenges and contribute to impactful technological advancements.



<!-- Hi, I am Chuyi (Sky) Hou. I am an HCI researcher and a Signal Processing and Machine Learning Engineer at Unmodal Research Inc. With a Master of Engineering in Mechanical and Industrial Engineering and a Bachelor of Applied Science in Engineering Science with a Robotics Option, I have a strong foundation in both theoretical and practical aspects of engineering.

My professional journey includes significant experience as a project team member and research assistant at the University of Toronto, where I honed my skills in Python, SQL, MATLAB, and ROS. At Unmodal Research Inc., I further developed my expertise in C programming, microcontroller programming, firmware development, and working with a wide range of sensors such as EMG, IMU, IR cameras, and force-sensitive resistors (FSR). I have also expanded my technical skill set to include Swift UI iOS app programming, UI/UX design, LLM cloud development and deployment, and Python GUI programming. Additionally, I have refined my creative abilities in product photography and video editing.

My experience spans developing cutting-edge Computer Vision and Machine Learning projects. Driven by a passion for innovation, I am dedicated to advancing the fields of signal processing and machine learning, leveraging my diverse skills to solve complex challenges and contribute to impactful technological advancements.

My **research interest** lies in:

Human-Computer Interaction (HCI), focusing on creating algorithms, tools, and models for seamless human-computer interactions. My work also explores UI/UX design and innovating ways to transform text-based interactions with large language models (LLMs) into more intuitive, text-less experiences for better outcomes. -->